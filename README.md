# DLG-attack-and-defense-implementation
This repository comprehensively implements the Deep Leakage from Gradients (DLG) attack and corresponding defence mechanisms. 
The DLG attack demonstrates how shared gradients in distributed learning can be exploited to reconstruct the original training data, posing significant privacy risks.

You can access the collab directly via [this](https://colab.research.google.com/drive/1WcVJcXotpFmH8uuyL6iZBMFH-NAZUUA1?usp=sharing) link!
